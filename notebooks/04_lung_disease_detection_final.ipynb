{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Lungs Disease Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:19:55.046882Z",
     "iopub.status.busy": "2025-09-15T03:19:55.046144Z",
     "iopub.status.idle": "2025-09-15T03:20:10.778350Z",
     "shell.execute_reply": "2025-09-15T03:20:10.777352Z",
     "shell.execute_reply.started": "2025-09-15T03:19:55.046862Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, random, numpy as np, tensorflow as tf\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"           # quieter logs\n",
    "# Optional if ONEDNN layout logs are noisy on CPU:\n",
    "# os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "# Force channels_last (you’re using 2D convs on spectrograms):\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "# Seeds\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# GPU memory growth (avoid OOM spikes)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for g in gpus: tf.config.experimental.set_memory_growth(g, True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup & Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:10.780468Z",
     "iopub.status.busy": "2025-09-15T03:20:10.779962Z",
     "iopub.status.idle": "2025-09-15T03:20:11.303956Z",
     "shell.execute_reply": "2025-09-15T03:20:11.303047Z",
     "shell.execute_reply.started": "2025-09-15T03:20:10.780407Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, random, math, time, glob, json, itertools\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "print(\"TF version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2) Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.305050Z",
     "iopub.status.busy": "2025-09-15T03:20:11.304767Z",
     "iopub.status.idle": "2025-09-15T03:20:11.309398Z",
     "shell.execute_reply": "2025-09-15T03:20:11.308734Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.305023Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3) Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.310321Z",
     "iopub.status.busy": "2025-09-15T03:20:11.310087Z",
     "iopub.status.idle": "2025-09-15T03:20:11.327143Z",
     "shell.execute_reply": "2025-09-15T03:20:11.326472Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.310305Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # Paths\n",
    "    data_dir        = \"/kaggle/input/asthma-detection-dataset-version-2/Asthma Detection Dataset Version 2/Asthma Detection Dataset Version 2\"\n",
    "    work_dir        = \"work_tf\"\n",
    "\n",
    "    # Classes\n",
    "    classes         = (\"Bronchial\", \"asthma\", \"copd\", \"healthy\", \"pneumonia\")\n",
    "    num_classes     = len(classes)\n",
    "\n",
    "    # Audio params\n",
    "    sample_rate     = 16000\n",
    "    duration_sec    = 4.0\n",
    "    n_fft           = 1024\n",
    "    hop_length      = 256\n",
    "    n_mels          = 128\n",
    "    fmin            = 20\n",
    "    fmax            = 8000\n",
    "    n_mfcc          = 20\n",
    "\n",
    "    # Augmentations\n",
    "    aug_prob        = 0.8\n",
    "    time_stretch    = (0.9, 1.1)    # +/- 10%\n",
    "    pitch_steps     = 2             # +/- 2 semitones\n",
    "    noise_snr_db    = (15, 30)      # target SNR range\n",
    "\n",
    "    # Training\n",
    "    batch_size      = 16\n",
    "    epochs          = 100\n",
    "    lr              = 3e-4\n",
    "    weight_decay    = 1e-4\n",
    "    early_stop_pat  = 12\n",
    "    mixed_precision = False\n",
    "    label_smoothing = 0.05\n",
    "    class_weights   = None\n",
    "\n",
    "    # Splits\n",
    "    test_size       = 0.15\n",
    "    val_size        = 0.15\n",
    "    seed            = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.329573Z",
     "iopub.status.busy": "2025-09-15T03:20:11.329076Z",
     "iopub.status.idle": "2025-09-15T03:20:11.348113Z",
     "shell.execute_reply": "2025-09-15T03:20:11.347314Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.329556Z"
    }
   },
   "outputs": [],
   "source": [
    "Path(CFG.work_dir).mkdir(parents=True, exist_ok=True)\n",
    "random.seed(CFG.seed); np.random.seed(CFG.seed); tf.random.set_seed(CFG.seed)\n",
    "\n",
    "if CFG.mixed_precision:\n",
    "    from tensorflow.keras import mixed_precision as mp\n",
    "    mp.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5) Derived values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.349280Z",
     "iopub.status.busy": "2025-09-15T03:20:11.349012Z",
     "iopub.status.idle": "2025-09-15T03:20:11.367084Z",
     "shell.execute_reply": "2025-09-15T03:20:11.366480Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.349261Z"
    }
   },
   "outputs": [],
   "source": [
    "def sec_to_samples(seconds, sr):\n",
    "    return int(round(seconds * sr))\n",
    "\n",
    "TARGET_SAMPLES = sec_to_samples(CFG.duration_sec, CFG.sample_rate)\n",
    "\n",
    "print(f\"Duration: {CFG.duration_sec}s | Sample Rate: {CFG.sample_rate}Hz | TARGET_SAMPLES: {TARGET_SAMPLES}\")\n",
    "print(f\"Classes: {CFG.classes} | Total: {CFG.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Index Files & Stratified Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Dataset Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.367867Z",
     "iopub.status.busy": "2025-09-15T03:20:11.367675Z",
     "iopub.status.idle": "2025-09-15T03:20:11.477650Z",
     "shell.execute_reply": "2025-09-15T03:20:11.476834Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.367854Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_index(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"Scan dataset and build a dataframe with paths and labels.\"\"\"\n",
    "    rows = []\n",
    "    for lbl in CFG.classes:\n",
    "        folder = Path(data_dir) / lbl\n",
    "        if not folder.exists():\n",
    "            print(f\"Warning: folder not found for class '{lbl}' -> {folder}\")\n",
    "            continue\n",
    "        for wav in folder.glob(\"*.wav\"):\n",
    "            rows.append({\"path\": str(wav), \"label\": lbl})\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        raise RuntimeError(\"No WAV files found. Please check data directory structure.\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Map labels to integer IDs\n",
    "    label2id = {c: i for i, c in enumerate(CFG.classes)}\n",
    "    id2label = {i: c for c, i in label2id.items()}\n",
    "    df[\"label_id\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "    print(f\"Found {len(df)} files across {len(df['label'].unique())} classes\")\n",
    "    return df, label2id, id2label\n",
    "\n",
    "# Build dataset index\n",
    "df_all, label2id, id2label = build_index(CFG.data_dir)\n",
    "\n",
    "df_all.head(), df_all[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.479239Z",
     "iopub.status.busy": "2025-09-15T03:20:11.478937Z",
     "iopub.status.idle": "2025-09-15T03:20:11.525394Z",
     "shell.execute_reply": "2025-09-15T03:20:11.524453Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.479217Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build dataset index\n",
    "df_all, label2id, id2label = build_index(CFG.data_dir)\n",
    "\n",
    "# Split stratified\n",
    "df_trainval, df_test = train_test_split(\n",
    "    df_all,\n",
    "    test_size=CFG.test_size,\n",
    "    stratify=df_all[\"label_id\"],\n",
    "    random_state=CFG.seed\n",
    ")\n",
    "\n",
    "val_rel = CFG.val_size / (1.0 - CFG.test_size)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_trainval,\n",
    "    test_size=val_rel,\n",
    "    stratify=df_trainval[\"label_id\"],\n",
    "    random_state=CFG.seed\n",
    ")\n",
    "\n",
    "# Save splits\n",
    "df_train.to_csv(f\"{CFG.work_dir}/train.csv\", index=False)\n",
    "df_val.to_csv(f\"{CFG.work_dir}/val.csv\", index=False)\n",
    "df_test.to_csv(f\"{CFG.work_dir}/test.csv\", index=False)\n",
    "\n",
    "# Save label mapping\n",
    "with open(f\"{CFG.work_dir}/labels.json\", \"w\") as f:\n",
    "    json.dump({\"label2id\": label2id, \"id2label\": id2label}, f, indent=2)\n",
    "\n",
    "# Summary\n",
    "print(\"Dataset split completed\")\n",
    "print(f\"Train: {len(df_train)} | Val: {len(df_val)} | Test: {len(df_test)}\")\n",
    "print(\"\\nTrain distribution:\\n\", df_train[\"label\"].value_counts())\n",
    "print(\"\\nVal distribution:\\n\", df_val[\"label\"].value_counts())\n",
    "print(\"\\nTest distribution:\\n\", df_test[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Audio I/O, Augmentation, and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Optional: quiet some TF graph layout warnings (set BEFORE TF imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.526543Z",
     "iopub.status.busy": "2025-09-15T03:20:11.526275Z",
     "iopub.status.idle": "2025-09-15T03:20:11.530985Z",
     "shell.execute_reply": "2025-09-15T03:20:11.530133Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.526523Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault(\"TF_ENABLE_LAYOUT_OPTIMIZER\", \"0\")  # purely optional\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) CFG-safe accessors (prevents AttributeError during tf.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.532171Z",
     "iopub.status.busy": "2025-09-15T03:20:11.531823Z",
     "iopub.status.idle": "2025-09-15T03:20:11.547969Z",
     "shell.execute_reply": "2025-09-15T03:20:11.547212Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.532141Z"
    }
   },
   "outputs": [],
   "source": [
    "def cfg_get(name, default):\n",
    "    # Assumes a global CFG object exists elsewhere in your notebook/script\n",
    "    return getattr(CFG, name, default)\n",
    "\n",
    "# Helper\n",
    "def sec_to_samples(s: float, sr: int) -> int:\n",
    "    return int(round(float(s) * int(sr)))\n",
    "\n",
    "TARGET_SAMPLES = sec_to_samples(cfg_get(\"duration_s\", 5.0), cfg_get(\"sample_rate\", 16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Loading and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.549023Z",
     "iopub.status.busy": "2025-09-15T03:20:11.548712Z",
     "iopub.status.idle": "2025-09-15T03:20:11.565285Z",
     "shell.execute_reply": "2025-09-15T03:20:11.564521Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.548997Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_wav(path: str, target_sr=None) -> np.ndarray:\n",
    "    if target_sr is None:\n",
    "        target_sr = cfg_get(\"sample_rate\", 16000)\n",
    "\n",
    "    y, sr = sf.read(path)\n",
    "    if y.ndim > 1:                   # stereo → mono\n",
    "        y = y.mean(axis=1)\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "def pad_or_trim(y: np.ndarray, target_len: int = None) -> np.ndarray:\n",
    "    if target_len is None:\n",
    "        target_len = TARGET_SAMPLES\n",
    "    n = len(y)\n",
    "    if n < target_len:\n",
    "        y = np.pad(y, (0, target_len - n), mode=\"constant\")\n",
    "    else:\n",
    "        y = y[:target_len]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.566072Z",
     "iopub.status.busy": "2025-09-15T03:20:11.565904Z",
     "iopub.status.idle": "2025-09-15T03:20:11.587443Z",
     "shell.execute_reply": "2025-09-15T03:20:11.586720Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.566059Z"
    }
   },
   "outputs": [],
   "source": [
    "def maybe_time_stretch(y: np.ndarray, sr=None) -> np.ndarray:\n",
    "    \"\"\"Random time stretching; mono-safe; librosa-compatible.\"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        if sr is None:\n",
    "            sr = cfg_get(\"sample_rate\", 16000)\n",
    "        span = cfg_get(\"time_stretch\", (0.9, 1.1))\n",
    "        rate = float(np.random.uniform(*span))\n",
    "        if y.ndim > 1:\n",
    "            y = librosa.to_mono(y)\n",
    "        y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "        y = librosa.effects.time_stretch(y, rate=rate)\n",
    "        y = pad_or_trim(y, TARGET_SAMPLES)\n",
    "    return y\n",
    "\n",
    "def maybe_pitch_shift(y: np.ndarray, sr=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Random pitch shift.\n",
    "    - Uses CFG.pitch_shift_steps = (lo, hi) if present (float range, e.g., (-3.0, 3.0))\n",
    "    - Otherwise falls back to CFG.pitch_steps = k (int), sampling from [-k, k] uniformly\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        if sr is None:\n",
    "            sr = cfg_get(\"sample_rate\", 16000)\n",
    "\n",
    "        ps_range = cfg_get(\"pitch_shift_steps\", None)\n",
    "        if ps_range is not None:\n",
    "            n_steps = float(np.random.uniform(*ps_range))\n",
    "        else:\n",
    "            k = int(cfg_get(\"pitch_steps\", 2))\n",
    "            n_steps = float(np.random.randint(-k, k + 1))  # includes 0\n",
    "\n",
    "        y = np.ascontiguousarray(y, dtype=np.float32)\n",
    "        y = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
    "        y = pad_or_trim(y, TARGET_SAMPLES)\n",
    "    return y\n",
    "\n",
    "def maybe_add_noise(y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Random noise addition based on SNR (in dB).\"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        snr_db_lo, snr_db_hi = cfg_get(\"noise_snr_db\", (10.0, 30.0))\n",
    "        snr_db = float(np.random.uniform(snr_db_lo, snr_db_hi))\n",
    "        sp = float(np.mean(y ** 2)) + 1e-9\n",
    "        npow = sp / (10 ** (snr_db / 10.0))\n",
    "        noise = np.random.normal(0.0, np.sqrt(npow), size=y.shape).astype(np.float32)\n",
    "        y = (y + noise).astype(np.float32)\n",
    "    return y\n",
    "\n",
    "def apply_augs(y: np.ndarray, sr=None) -> np.ndarray:\n",
    "    \"\"\"Apply all augmentations with a single coin flip gate (CFG.aug_prob).\"\"\"\n",
    "    if sr is None:\n",
    "        sr = cfg_get(\"sample_rate\", 16000)\n",
    "    if np.random.rand() < cfg_get(\"aug_prob\", 0.8):\n",
    "        y = maybe_time_stretch(y, sr)\n",
    "        y = maybe_pitch_shift(y, sr)\n",
    "        y = maybe_add_noise(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.588532Z",
     "iopub.status.busy": "2025-09-15T03:20:11.588279Z",
     "iopub.status.idle": "2025-09-15T03:20:11.604735Z",
     "shell.execute_reply": "2025-09-15T03:20:11.603968Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.588507Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_melspec(y: np.ndarray, sr=None) -> np.ndarray:\n",
    "    if sr is None:\n",
    "        sr = cfg_get(\"sample_rate\", 16000)\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_fft=cfg_get(\"n_fft\", 1024),\n",
    "        hop_length=cfg_get(\"hop_length\", 256),\n",
    "        n_mels=cfg_get(\"n_mels\", 128),\n",
    "        fmin=cfg_get(\"fmin\", 20.0),\n",
    "        fmax=cfg_get(\"fmax\", sr // 2),\n",
    "        power=2.0,\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    S_db = (S_db - S_db.mean()) / (S_db.std() + 1e-6)  # standardize per sample\n",
    "    return S_db.astype(np.float32)  # (n_mels, time)\n",
    "\n",
    "def compute_handcrafted(y: np.ndarray, sr=None) -> np.ndarray:\n",
    "    if sr is None:\n",
    "        sr = cfg_get(\"sample_rate\", 16000)\n",
    "\n",
    "    n_fft = cfg_get(\"n_fft\", 1024)\n",
    "    hop = cfg_get(\"hop_length\", 256)\n",
    "    fmin = cfg_get(\"fmin\", 20.0)\n",
    "    fmax = cfg_get(\"fmax\", sr // 2)\n",
    "    n_mfcc = cfg_get(\"n_mfcc\", 20)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop, fmin=fmin, fmax=fmax)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=n_fft, hop_length=hop)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y, hop_length=hop)\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=n_fft, hop_length=hop)\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr, n_fft=n_fft, hop_length=hop)\n",
    "\n",
    "    def agg(X):\n",
    "        # mean+std across frames\n",
    "        return np.concatenate([X.mean(axis=1), X.std(axis=1)])\n",
    "\n",
    "    feats = np.concatenate([agg(mfcc), agg(chroma), agg(zcr), agg(centroid), agg(bandwidth)]).astype(np.float32)\n",
    "    return feats  # ~ 2*(n_mfcc + 12 + 1 + 1 + 1) = 2*(n_mfcc + 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:11.608259Z",
     "iopub.status.busy": "2025-09-15T03:20:11.608049Z",
     "iopub.status.idle": "2025-09-15T03:20:12.001728Z",
     "shell.execute_reply": "2025-09-15T03:20:12.001097Z",
     "shell.execute_reply.started": "2025-09-15T03:20:11.608244Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset path\n",
    "data_path = \"/kaggle/input/asthma-detection-dataset-version-2/Asthma Detection Dataset Version 2/Asthma Detection Dataset Version 2\"\n",
    "\n",
    "# Class distribution\n",
    "classes = os.listdir(data_path)\n",
    "samples_per_class = {cls: len(os.listdir(os.path.join(data_path, cls))) for cls in classes}\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "print(f\"Total Classes: {len(classes)}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "print(f\"Samples per class: {samples_per_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Plot class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:12.002800Z",
     "iopub.status.busy": "2025-09-15T03:20:12.002442Z",
     "iopub.status.idle": "2025-09-15T03:20:12.268625Z",
     "shell.execute_reply": "2025-09-15T03:20:12.267813Z",
     "shell.execute_reply.started": "2025-09-15T03:20:12.002785Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=list(samples_per_class.keys()), y=list(samples_per_class.values()))\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Show waveform and spectrogram for a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:12.269441Z",
     "iopub.status.busy": "2025-09-15T03:20:12.269254Z",
     "iopub.status.idle": "2025-09-15T03:20:12.273652Z",
     "shell.execute_reply": "2025-09-15T03:20:12.272912Z",
     "shell.execute_reply.started": "2025-09-15T03:20:12.269426Z"
    }
   },
   "outputs": [],
   "source": [
    "example_class = classes[0]\n",
    "example_file = os.path.join(data_path, example_class, os.listdir(os.path.join(data_path, example_class))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:12.274614Z",
     "iopub.status.busy": "2025-09-15T03:20:12.274357Z",
     "iopub.status.idle": "2025-09-15T03:20:25.037199Z",
     "shell.execute_reply": "2025-09-15T03:20:25.036364Z",
     "shell.execute_reply.started": "2025-09-15T03:20:12.274594Z"
    }
   },
   "outputs": [],
   "source": [
    "y, sr = librosa.load(example_file)\n",
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title(f\"Waveform - {example_class}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:25.038546Z",
     "iopub.status.busy": "2025-09-15T03:20:25.038003Z",
     "iopub.status.idle": "2025-09-15T03:20:25.543173Z",
     "shell.execute_reply": "2025-09-15T03:20:25.542477Z",
     "shell.execute_reply.started": "2025-09-15T03:20:25.038526Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title(f\"Spectrogram - {example_class}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) tf.data Pipelines (Generators with Augment for Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Inspect handcrafted feature dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:25.544262Z",
     "iopub.status.busy": "2025-09-15T03:20:25.544004Z",
     "iopub.status.idle": "2025-09-15T03:20:26.771986Z",
     "shell.execute_reply": "2025-09-15T03:20:26.771218Z",
     "shell.execute_reply.started": "2025-09-15T03:20:25.544243Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_path = df_train.iloc[0][\"path\"]\n",
    "y_tmp = pad_or_trim(load_wav(tmp_path))\n",
    "hand_dim = compute_handcrafted(y_tmp).shape[0]\n",
    "print(\"Handcrafted feature dim:\", hand_dim)\n",
    "\n",
    "# Label mappings (already saved in labels.json earlier)\n",
    "label2id = {c: i for i, c in enumerate(CFG.classes)}\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Example extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:26.773100Z",
     "iopub.status.busy": "2025-09-15T03:20:26.772847Z",
     "iopub.status.idle": "2025-09-15T03:20:26.778916Z",
     "shell.execute_reply": "2025-09-15T03:20:26.778053Z",
     "shell.execute_reply.started": "2025-09-15T03:20:26.773083Z"
    }
   },
   "outputs": [],
   "source": [
    "def example_from_row(row, training=False):\n",
    "    \"\"\"Extract mel-spectrogram + handcrafted features + label from a single row.\"\"\"\n",
    "    y = pad_or_trim(load_wav(row[\"path\"]))\n",
    "    if training:\n",
    "        y = apply_augs(y)\n",
    "    \n",
    "    mel = compute_melspec(y)          # (n_mels, T)\n",
    "    hand = compute_handcrafted(y)     # (hand_dim,)\n",
    "    lbl = int(row[\"label_id\"])\n",
    "    \n",
    "    # CNN expects (H, W, 1)\n",
    "    mel = np.expand_dims(mel, axis=-1)   # (n_mels, T, 1)\n",
    "    return mel, hand, lbl\n",
    "\n",
    "def generator_from_df(df: pd.DataFrame, training=False):\n",
    "    for _, row in df.iterrows():\n",
    "        yield example_from_row(row, training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Dataset Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:26.779938Z",
     "iopub.status.busy": "2025-09-15T03:20:26.779750Z",
     "iopub.status.idle": "2025-09-15T03:20:26.800194Z",
     "shell.execute_reply": "2025-09-15T03:20:26.799653Z",
     "shell.execute_reply.started": "2025-09-15T03:20:26.779923Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_dataset(df: pd.DataFrame, training=False, batch_size=CFG.batch_size):\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: generator_from_df(df, training=training),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(CFG.n_mels, None, 1), dtype=tf.float32),   # mel\n",
    "            tf.TensorSpec(shape=(hand_dim,), dtype=tf.float32),             # handcrafted\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int32),                        # label\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.shuffle(1024, seed=CFG.seed, reshuffle_each_iteration=True)\n",
    "    \n",
    "    # Pad mel time dimension across batch\n",
    "    ds = ds.padded_batch(\n",
    "        batch_size,\n",
    "        padded_shapes=(\n",
    "            (CFG.n_mels, None, 1),   # mel spectrograms (pad time dim only)\n",
    "            (hand_dim,),             # handcrafted features (fixed)\n",
    "            ()                       # labels\n",
    "        ),\n",
    "        padding_values=(\n",
    "            0.0,                     # mel\n",
    "            0.0,                     # handcrafted\n",
    "            np.int32(0)              # labels\n",
    "        )\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:20:26.801395Z",
     "iopub.status.busy": "2025-09-15T03:20:26.800929Z",
     "iopub.status.idle": "2025-09-15T03:21:52.797115Z",
     "shell.execute_reply": "2025-09-15T03:21:52.796468Z",
     "shell.execute_reply.started": "2025-09-15T03:20:26.801372Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = make_dataset(df_train, training=True)\n",
    "val_ds   = make_dataset(df_val, training=False)\n",
    "test_ds  = make_dataset(df_test, training=False)\n",
    "\n",
    "print(\"tf.data pipelines ready:\")\n",
    "print(\"Train batches:\", len(list(train_ds)))\n",
    "print(\"Val batches:\", len(list(val_ds)))\n",
    "print(\"Test batches:\", len(list(test_ds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Model: CNN → BiLSTM → Attention (Mel branch) + MLP (handcrafted) → Late Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Attention layer (temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:21:52.798145Z",
     "iopub.status.busy": "2025-09-15T03:21:52.797901Z",
     "iopub.status.idle": "2025-09-15T03:21:52.802950Z",
     "shell.execute_reply": "2025-09-15T03:21:52.802364Z",
     "shell.execute_reply.started": "2025-09-15T03:21:52.798120Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(layers.Layer):\n",
    "    def __init__(self, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = layers.Dense(d_model, activation=\"tanh\")\n",
    "        self.v = layers.Dense(1, use_bias=False)\n",
    "\n",
    "    def call(self, x):  # x: (B,T,D)\n",
    "        s = self.w(x)                 # (B,T,D)\n",
    "        s = self.v(s)                 # (B,T,1)\n",
    "        a = tf.nn.softmax(s, axis=1)  # (B,T,1)\n",
    "        ctx = tf.reduce_sum(x * a, axis=1)  # (B,D)\n",
    "        return ctx, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Convolutional Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:21:52.803802Z",
     "iopub.status.busy": "2025-09-15T03:21:52.803566Z",
     "iopub.status.idle": "2025-09-15T03:21:52.819185Z",
     "shell.execute_reply": "2025-09-15T03:21:52.818466Z",
     "shell.execute_reply.started": "2025-09-15T03:21:52.803781Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters):\n",
    "    x = layers.Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:21:52.820144Z",
     "iopub.status.busy": "2025-09-15T03:21:52.819965Z",
     "iopub.status.idle": "2025-09-15T03:21:52.830167Z",
     "shell.execute_reply": "2025-09-15T03:21:52.829738Z",
     "shell.execute_reply.started": "2025-09-15T03:21:52.820130Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(hand_dim: int, num_classes=len(CFG.classes)) -> keras.Model:\n",
    "    # Inputs\n",
    "    mel_in  = layers.Input(shape=(CFG.n_mels, None, 1), name=\"mel\")     # (M,T,1)\n",
    "    hand_in = layers.Input(shape=(hand_dim,), name=\"handcrafted\")       # (D,)\n",
    "\n",
    "    # CNN over Mel\n",
    "    x = conv_block(mel_in, 32)\n",
    "    x = conv_block(x, 64)\n",
    "    x = conv_block(x, 128)  # final conv block\n",
    "\n",
    "    # Save last conv for Grad-CAM++\n",
    "    x = layers.Lambda(lambda z: z, name=\"conv_tail_identity\")(x)\n",
    "\n",
    "    # (B, M', T', C) -> (B, T', M', C)\n",
    "    x = layers.Permute((2, 1, 3))(x)\n",
    "\n",
    "    # Flatten freq*channels -> features, time stays\n",
    "    x = layers.TimeDistributed(layers.Flatten())(x)  # (B, T', F)\n",
    "\n",
    "    # Temporal modeling\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)  # (B,T,256)\n",
    "\n",
    "    # Attention\n",
    "    ctx, attn = AdditiveAttention(256, name=\"temporal_attention\")(x)      # ctx: (B,256)\n",
    "\n",
    "    mel_emb = layers.Dropout(0.3)(ctx)\n",
    "\n",
    "    # --- Handcrafted branch ---\n",
    "    h = layers.Dense(256)(hand_in)\n",
    "    h = layers.BatchNormalization()(h)\n",
    "    h = layers.ReLU()(h)\n",
    "    h = layers.Dropout(0.3)(h)\n",
    "    h = layers.Dense(128, activation=\"relu\")(h)\n",
    "\n",
    "    # Late fusion\n",
    "    z = layers.Concatenate()([mel_emb, h])        # (B, 256+128)\n",
    "    z = layers.Dense(256, activation=\"relu\")(z)\n",
    "    z = layers.Dropout(0.3)(z)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(z)\n",
    "\n",
    "    # Compile model\n",
    "    model = keras.Model(inputs=[mel_in, hand_in], outputs=[out], name=\"HybridCNN_BiLSTM_Attn\")\n",
    "    opt = keras.optimizers.Adam(learning_rate=CFG.lr)\n",
    "    model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4) Dataset Formatting and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:21:52.831365Z",
     "iopub.status.busy": "2025-09-15T03:21:52.831107Z",
     "iopub.status.idle": "2025-09-15T03:21:52.848064Z",
     "shell.execute_reply": "2025-09-15T03:21:52.847321Z",
     "shell.execute_reply.started": "2025-09-15T03:21:52.831343Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset formatting\n",
    "def split_xy(ds):\n",
    "    # Map from (mel, hand, y) → ((mel, hand), y)\n",
    "    return ds.map(lambda mel, hand, y: ((mel, hand), y), \n",
    "                  num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:21:52.849616Z",
     "iopub.status.busy": "2025-09-15T03:21:52.848959Z",
     "iopub.status.idle": "2025-09-15T03:21:54.047613Z",
     "shell.execute_reply": "2025-09-15T03:21:54.047008Z",
     "shell.execute_reply.started": "2025-09-15T03:21:52.849590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure hand_dim is computed correctly\n",
    "tmp_path = df_train.iloc[0][\"path\"]\n",
    "y_tmp = pad_or_trim(load_wav(tmp_path))\n",
    "hand_dim = compute_handcrafted(y_tmp).shape[0]\n",
    "print(\"Handcrafted feature dim:\", hand_dim)  # should be > 0, e.g. 70\n",
    "\n",
    "# Rebuild model with correct input shape\n",
    "model = build_model(hand_dim=hand_dim, num_classes=len(CFG.classes))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:21:54.048521Z",
     "iopub.status.busy": "2025-09-15T03:21:54.048275Z",
     "iopub.status.idle": "2025-09-15T03:21:54.087916Z",
     "shell.execute_reply": "2025-09-15T03:21:54.087372Z",
     "shell.execute_reply.started": "2025-09-15T03:21:54.048495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare datasets again (they must match new model inputs)\n",
    "train_xy = split_xy(train_ds)\n",
    "val_xy   = split_xy(val_ds)\n",
    "test_xy  = split_xy(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:21:54.088720Z",
     "iopub.status.busy": "2025-09-15T03:21:54.088515Z",
     "iopub.status.idle": "2025-09-15T03:21:54.093376Z",
     "shell.execute_reply": "2025-09-15T03:21:54.092590Z",
     "shell.execute_reply.started": "2025-09-15T03:21:54.088706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "ckpt_path = f\"{CFG.work_dir}/best_model.keras\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        ckpt_path, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\"\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        patience=CFG.early_stop_pat, restore_best_weights=True,\n",
    "        monitor=\"val_accuracy\", mode=\"max\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.5, patience=4, monitor=\"val_loss\", mode=\"min\", verbose=1\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5) Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T03:21:54.094339Z",
     "iopub.status.busy": "2025-09-15T03:21:54.094136Z",
     "iopub.status.idle": "2025-09-15T04:39:30.402333Z",
     "shell.execute_reply": "2025-09-15T04:39:30.401732Z",
     "shell.execute_reply.started": "2025-09-15T03:21:54.094321Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_xy,\n",
    "    validation_data=val_xy,\n",
    "    epochs=CFG.epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:30.403321Z",
     "iopub.status.busy": "2025-09-15T04:39:30.403053Z",
     "iopub.status.idle": "2025-09-15T04:39:30.408086Z",
     "shell.execute_reply": "2025-09-15T04:39:30.407609Z",
     "shell.execute_reply.started": "2025-09-15T04:39:30.403302Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Collect predictions\n",
    "def collect_preds(model, ds) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y_true, y_prob = [], []\n",
    "    for (mel, hand), y in ds:\n",
    "        p = model.predict((mel, hand), verbose=0)\n",
    "        y_true.append(y.numpy())\n",
    "        y_prob.append(p)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_prob = np.concatenate(y_prob)\n",
    "    return y_true, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:30.409093Z",
     "iopub.status.busy": "2025-09-15T04:39:30.408870Z",
     "iopub.status.idle": "2025-09-15T04:39:40.152826Z",
     "shell.execute_reply": "2025-09-15T04:39:40.152246Z",
     "shell.execute_reply.started": "2025-09-15T04:39:30.409071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "yv_true, yv_prob = collect_preds(model, val_xy)\n",
    "yv_pred = yv_prob.argmax(axis=1)\n",
    "\n",
    "print(\"Validation Report:\")\n",
    "print(classification_report(yv_true, yv_pred, target_names=CFG.classes, zero_division=0))\n",
    "\n",
    "cm_val = confusion_matrix(yv_true, yv_pred)\n",
    "print(\"\\n Validation Confusion Matrix:\")\n",
    "display(pd.DataFrame(cm_val, index=CFG.classes, columns=CFG.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:40.153827Z",
     "iopub.status.busy": "2025-09-15T04:39:40.153578Z",
     "iopub.status.idle": "2025-09-15T04:39:48.980703Z",
     "shell.execute_reply": "2025-09-15T04:39:48.980106Z",
     "shell.execute_reply.started": "2025-09-15T04:39:40.153801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "yt_true, yt_prob = collect_preds(model, test_xy)\n",
    "yt_pred = yt_prob.argmax(axis=1)\n",
    "\n",
    "print(\"\\n Test Report:\")\n",
    "print(classification_report(yt_true, yt_pred, target_names=CFG.classes, zero_division=0))\n",
    "\n",
    "cm_test = confusion_matrix(yt_true, yt_pred)\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "display(pd.DataFrame(cm_test, index=CFG.classes, columns=CFG.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:48.981614Z",
     "iopub.status.busy": "2025-09-15T04:39:48.981379Z",
     "iopub.status.idle": "2025-09-15T04:39:49.005833Z",
     "shell.execute_reply": "2025-09-15T04:39:49.005254Z",
     "shell.execute_reply.started": "2025-09-15T04:39:48.981597Z"
    }
   },
   "outputs": [],
   "source": [
    "# One-vs-rest ROC-AUC (macro)\n",
    "Y_ovr_val = np.eye(len(CFG.classes))[yv_true]\n",
    "Y_ovr_test = np.eye(len(CFG.classes))[yt_true]\n",
    "\n",
    "val_aucs, test_aucs = [], []\n",
    "for c in range(len(CFG.classes)):\n",
    "    try:\n",
    "        val_aucs.append(roc_auc_score(Y_ovr_val[:, c], yv_prob[:, c]))\n",
    "        test_aucs.append(roc_auc_score(Y_ovr_test[:, c], yt_prob[:, c]))\n",
    "    except ValueError:\n",
    "        # Happens if a class is missing in y_true\n",
    "        continue\n",
    "\n",
    "if val_aucs:\n",
    "    print(f\"\\nVal Macro ROC-AUC: {np.mean(val_aucs):.4f}\")\n",
    "if test_aucs:\n",
    "    print(f\"Test Macro ROC-AUC: {np.mean(test_aucs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:49.006682Z",
     "iopub.status.busy": "2025-09-15T04:39:49.006496Z",
     "iopub.status.idle": "2025-09-15T04:39:49.272826Z",
     "shell.execute_reply": "2025-09-15T04:39:49.272092Z",
     "shell.execute_reply.started": "2025-09-15T04:39:49.006658Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Training Curves\n",
    "plt.figure(figsize=(8, 5))\n",
    "pd.DataFrame(history.history)[[\"loss\", \"val_loss\", \"accuracy\", \"val_accuracy\"]].plot(grid=True, linewidth=2)\n",
    "plt.title(\"Training Curves\", fontsize=14)\n",
    "plt.ylabel(\"Loss / Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:49.273964Z",
     "iopub.status.busy": "2025-09-15T04:39:49.273667Z",
     "iopub.status.idle": "2025-09-15T04:39:49.495910Z",
     "shell.execute_reply": "2025-09-15T04:39:49.495239Z",
     "shell.execute_reply.started": "2025-09-15T04:39:49.273937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix (Test)\n",
    "cm = confusion_matrix(yt_true, yt_pred)\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]  # normalized version\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_norm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "    xticklabels=CFG.classes, yticklabels=CFG.classes,\n",
    "    cbar=True, square=True\n",
    ")\n",
    "plt.xlabel(\"Predicted\", fontsize=12)\n",
    "plt.ylabel(\"True\", fontsize=12)\n",
    "plt.title(\"Test Confusion Matrix (Normalized)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:49.497002Z",
     "iopub.status.busy": "2025-09-15T04:39:49.496747Z",
     "iopub.status.idle": "2025-09-15T04:39:49.502390Z",
     "shell.execute_reply": "2025-09-15T04:39:49.501761Z",
     "shell.execute_reply.started": "2025-09-15T04:39:49.496979Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract final metrics from history safely\n",
    "final_train_acc = history.history.get(\"accuracy\", [None])[-1]\n",
    "final_train_loss = history.history.get(\"loss\", [None])[-1]\n",
    "final_val_acc = history.history.get(\"val_accuracy\", [None])[-1]\n",
    "final_val_loss = history.history.get(\"val_loss\", [None])[-1]\n",
    "\n",
    "print(\"\\n Final Training & Validation Metrics: \")\n",
    "print(f\" Training Accuracy   : {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\" Training Loss       : {final_train_loss:.4f}\")\n",
    "print(f\" Validation Accuracy : {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "print(f\" Validation Loss     : {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:49.503844Z",
     "iopub.status.busy": "2025-09-15T04:39:49.503155Z",
     "iopub.status.idle": "2025-09-15T04:39:49.889680Z",
     "shell.execute_reply": "2025-09-15T04:39:49.888991Z",
     "shell.execute_reply.started": "2025-09-15T04:39:49.503822Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy', marker='s')\n",
    "plt.title(\"Accuracy Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', marker='s')\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:49.891050Z",
     "iopub.status.busy": "2025-09-15T04:39:49.890555Z",
     "iopub.status.idle": "2025-09-15T04:39:57.654603Z",
     "shell.execute_reply": "2025-09-15T04:39:57.653821Z",
     "shell.execute_reply.started": "2025-09-15T04:39:49.891026Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import itertools\n",
    "\n",
    "# 1) Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(val_xy, verbose=0)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:39:57.655538Z",
     "iopub.status.busy": "2025-09-15T04:39:57.655270Z",
     "iopub.status.idle": "2025-09-15T04:40:14.993212Z",
     "shell.execute_reply": "2025-09-15T04:40:14.992469Z",
     "shell.execute_reply.started": "2025-09-15T04:39:57.655515Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2) Get predictions & true labels from val_xy\n",
    "y_pred_probs = model.predict(val_xy, verbose=0)   # shape: (N, num_classes)\n",
    "y_true = np.concatenate([y.numpy() for (_, _), y in val_xy], axis=0)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Class names (from CFG)\n",
    "classes = list(CFG.classes)\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:40:14.997912Z",
     "iopub.status.busy": "2025-09-15T04:40:14.997313Z",
     "iopub.status.idle": "2025-09-15T04:40:15.009073Z",
     "shell.execute_reply": "2025-09-15T04:40:15.008462Z",
     "shell.execute_reply.started": "2025-09-15T04:40:14.997893Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3) Classification report\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=classes, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:40:15.009960Z",
     "iopub.status.busy": "2025-09-15T04:40:15.009727Z",
     "iopub.status.idle": "2025-09-15T04:40:15.239083Z",
     "shell.execute_reply": "2025-09-15T04:40:15.238320Z",
     "shell.execute_reply.started": "2025-09-15T04:40:15.009934Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4) Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(num_classes)\n",
    "plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Annotate cells\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j],\n",
    "             ha=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "             fontsize=9)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:40:15.240671Z",
     "iopub.status.busy": "2025-09-15T04:40:15.239980Z",
     "iopub.status.idle": "2025-09-15T04:40:15.450203Z",
     "shell.execute_reply": "2025-09-15T04:40:15.449571Z",
     "shell.execute_reply.started": "2025-09-15T04:40:15.240646Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5) ROC curves (one-vs-rest)\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))  # shape: (N, C)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "auc_per_class = []\n",
    "\n",
    "for i, cls_name in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_per_class.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{cls_name} (AUC={roc_auc:.3f})\")\n",
    "\n",
    "# Micro-average ROC\n",
    "fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), y_pred_probs.ravel())\n",
    "auc_micro = auc(fpr_micro, tpr_micro)\n",
    "plt.plot(fpr_micro, tpr_micro, linestyle=\"--\", lw=2, label=f\"Micro-average (AUC={auc_micro:.3f})\")\n",
    "\n",
    "# Macro-average ROC\n",
    "auc_macro = np.mean(auc_per_class)\n",
    "plt.plot([0,1],[0,1],\"k--\", lw=1)\n",
    "plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves (Validation)\")\n",
    "plt.legend(loc=\"lower right\", fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPer-class AUC: {dict(zip(classes, [round(a, 4) for a in auc_per_class]))}\")\n",
    "print(f\"Micro-average AUC: {auc_micro:.4f}\")\n",
    "print(f\"Macro-average AUC: {auc_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:40:15.450987Z",
     "iopub.status.busy": "2025-09-15T04:40:15.450793Z",
     "iopub.status.idle": "2025-09-15T04:41:03.386453Z",
     "shell.execute_reply": "2025-09-15T04:41:03.385727Z",
     "shell.execute_reply.started": "2025-09-15T04:40:15.450972Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import itertools\n",
    "\n",
    "def evaluate_and_plot(model, ds, classes, set_name=\"Validation\"):\n",
    "    \"\"\"Evaluate model on a dataset, print metrics, and plot confusion matrix + ROC curves.\"\"\"\n",
    "    # ----- 1) Evaluate -----\n",
    "    loss, acc = model.evaluate(ds, verbose=0)\n",
    "    print(f\"\\n{set_name} Loss: {loss:.4f}\")\n",
    "    print(f\"{set_name} Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # ----- 2) Predictions -----\n",
    "    y_pred_probs = model.predict(ds, verbose=0)\n",
    "    y_true = np.concatenate([y.numpy() for (_, _), y in ds], axis=0)\n",
    "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # ----- 3) Classification Report -----\n",
    "    print(f\"\\nClassification Report ({set_name}):\")\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=classes, digits=4))\n",
    "\n",
    "    # ----- 4) Confusion Matrix -----\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix ({set_name})\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 ha=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=9)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ----- 5) ROC Curves -----\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n",
    "    plt.figure(figsize=(8,6))\n",
    "    auc_per_class = []\n",
    "\n",
    "    for i, cls_name in enumerate(classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_per_class.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f\"{cls_name} (AUC={roc_auc:.3f})\")\n",
    "\n",
    "    # Micro-average ROC\n",
    "    fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), y_pred_probs.ravel())\n",
    "    auc_micro = auc(fpr_micro, tpr_micro)\n",
    "    plt.plot(fpr_micro, tpr_micro, linestyle=\"--\", lw=2, label=f\"Micro-average (AUC={auc_micro:.3f})\")\n",
    "\n",
    "    # Macro-average ROC\n",
    "    auc_macro = np.mean(auc_per_class)\n",
    "    plt.plot([0,1],[0,1],\"k--\", lw=1)\n",
    "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curves ({set_name})\")\n",
    "    plt.legend(loc=\"lower right\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nPer-class AUC ({set_name}): {dict(zip(classes, [round(a, 4) for a in auc_per_class]))}\")\n",
    "    print(f\"Micro-average AUC ({set_name}): {auc_micro:.4f}\")\n",
    "    print(f\"Macro-average AUC ({set_name}): {auc_macro:.4f}\")\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "# Run for Validation and Test\n",
    "classes = list(CFG.classes)\n",
    "\n",
    "val_loss, val_acc = evaluate_and_plot(model, val_xy, classes, set_name=\"Validation\")\n",
    "test_loss, test_acc = evaluate_and_plot(model, test_xy, classes, set_name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:03.387515Z",
     "iopub.status.busy": "2025-09-15T04:41:03.387255Z",
     "iopub.status.idle": "2025-09-15T04:41:03.610453Z",
     "shell.execute_reply": "2025-09-15T04:41:03.609794Z",
     "shell.execute_reply.started": "2025-09-15T04:41:03.387496Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Normalize by row (true labels)\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", \n",
    "            xticklabels=CFG.classes, yticklabels=CFG.classes, \n",
    "            cmap=\"Blues\", cbar=True)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) XAI: Grad-CAM (for dual-input model: mel + handcrafted features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:03.611905Z",
     "iopub.status.busy": "2025-09-15T04:41:03.611290Z",
     "iopub.status.idle": "2025-09-15T04:41:03.625823Z",
     "shell.execute_reply": "2025-09-15T04:41:03.625253Z",
     "shell.execute_reply.started": "2025-09-15T04:41:03.611880Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _find_last_conv_before_rnn(model):\n",
    "    \"\"\"Return the last Conv2D layer before any RNN. If none, return last Conv2D overall.\"\"\"\n",
    "    rnn_types = (tf.keras.layers.LSTM, tf.keras.layers.GRU, tf.keras.layers.SimpleRNN, tf.keras.layers.RNN)\n",
    "    last_rnn_idx, last_conv_idx = None, None\n",
    "    layers_list = list(model.layers)\n",
    "\n",
    "    for i, layer in enumerate(layers_list):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            last_conv_idx = i\n",
    "        if isinstance(layer, rnn_types):\n",
    "            last_rnn_idx = i\n",
    "            break\n",
    "\n",
    "    if last_rnn_idx is None:\n",
    "        if last_conv_idx is None:\n",
    "            raise ValueError(\"No Conv2D layer found in model.\")\n",
    "        return layers_list[last_conv_idx].name\n",
    "    else:\n",
    "        for i in range(last_rnn_idx - 1, -1, -1):\n",
    "            if isinstance(layers_list[i], tf.keras.layers.Conv2D):\n",
    "                return layers_list[i].name\n",
    "        if last_conv_idx is None:\n",
    "            raise ValueError(\"No Conv2D layer found in model.\")\n",
    "        return layers_list[last_conv_idx].name\n",
    "\n",
    "\n",
    "def _pack_inputs_for_model(model, mel_batch, hand_batch):\n",
    "    \"\"\"Return inputs in correct form for the model (dict or list).\"\"\"\n",
    "    mel_batch = tf.convert_to_tensor(mel_batch)\n",
    "    hand_batch = tf.convert_to_tensor(hand_batch)\n",
    "    try:\n",
    "        names = [str(inp.name).split(\":\")[0].split(\"/\")[-1] for inp in model.inputs]\n",
    "        if \"mel\" in names and \"handcrafted\" in names:\n",
    "            return {\"mel\": mel_batch, \"handcrafted\": hand_batch}\n",
    "    except Exception:\n",
    "        pass\n",
    "    return [mel_batch, hand_batch]\n",
    "\n",
    "\n",
    "def grad_cam(model, mel_batch, hand_batch, class_idx=None, conv_layer_name=None):\n",
    "    \"\"\"\n",
    "    Compute Grad-CAM heatmaps for a batch.\n",
    "    Returns:\n",
    "      heatmaps_resized: np.array (B, M, T)\n",
    "      chosen_classes: np.array (B,)\n",
    "      preds_np: np.array (B, C)\n",
    "    \"\"\"\n",
    "    if conv_layer_name is None:\n",
    "        conv_layer_name = _find_last_conv_before_rnn(model)\n",
    "\n",
    "    grad_model = tf.keras.Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    batch_inputs = _pack_inputs_for_model(model, mel_batch, hand_batch)\n",
    "    conv_out0, preds0 = grad_model(batch_inputs, training=False)\n",
    "    if isinstance(preds0, (list, tuple)):\n",
    "        preds0 = preds0[0]\n",
    "\n",
    "    preds0_np = preds0.numpy()\n",
    "    B, C = preds0_np.shape\n",
    "\n",
    "    # Decide target class for each sample\n",
    "    if class_idx is None:\n",
    "        cls_np = np.argmax(preds0_np, axis=1).astype(np.int32)\n",
    "    else:\n",
    "        cls_np = np.array(class_idx).reshape(-1).astype(np.int32)\n",
    "\n",
    "    class_one_hot = tf.convert_to_tensor(np.eye(C, dtype=np.float32)[cls_np])\n",
    "\n",
    "    # Gradient calculation\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, preds = grad_model(batch_inputs, training=False)\n",
    "        if isinstance(preds, (list, tuple)):\n",
    "            preds = preds[0]\n",
    "        tape.watch(conv_out)\n",
    "        y_c = tf.reduce_sum(preds * class_one_hot, axis=1)\n",
    "\n",
    "    grads = tape.gradient(y_c, conv_out)\n",
    "    if grads is None:\n",
    "        raise RuntimeError(\"Gradients are None. Check conv layer connectivity.\")\n",
    "\n",
    "    # Global average pooling over gradients\n",
    "    weights = tf.reduce_mean(grads, axis=[1, 2])  # (B,K)\n",
    "    cam = tf.reduce_sum(tf.reshape(weights, (-1, 1, 1, tf.shape(conv_out)[-1])) * conv_out, axis=-1)\n",
    "    cam = tf.nn.relu(cam)\n",
    "\n",
    "    # Normalize each heatmap\n",
    "    eps = 1e-8\n",
    "    cam_min = tf.reduce_min(cam, axis=[1, 2], keepdims=True)\n",
    "    cam_max = tf.reduce_max(cam, axis=[1, 2], keepdims=True)\n",
    "    cam_norm = (cam - cam_min) / (cam_max - cam_min + eps)\n",
    "\n",
    "    # Resize CAMs to mel spectrogram shape\n",
    "    M, T = tf.shape(mel_batch)[1], tf.shape(mel_batch)[2]\n",
    "    cam_resized = tf.image.resize(cam_norm[..., tf.newaxis], size=(M, T), method=\"bilinear\")\n",
    "    return tf.squeeze(cam_resized, axis=-1).numpy(), cls_np, preds0_np\n",
    "\n",
    "\n",
    "def visualize_cam_on_mel(mel, cam, title=\"Grad-CAM\", cmap_mel=\"magma\", cmap_cam=\"jet\", alpha=0.4):\n",
    "    \"\"\"Overlay Grad-CAM heatmap on mel spectrogram.\"\"\"\n",
    "    mel2d = mel[..., 0] if mel.ndim == 3 else mel\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.imshow(mel2d, origin=\"lower\", aspect=\"auto\", cmap=cmap_mel)\n",
    "    plt.imshow(cam, origin=\"lower\", aspect=\"auto\", cmap=cmap_cam, alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:03.627371Z",
     "iopub.status.busy": "2025-09-15T04:41:03.626566Z",
     "iopub.status.idle": "2025-09-15T04:41:08.151489Z",
     "shell.execute_reply": "2025-09-15T04:41:08.150773Z",
     "shell.execute_reply.started": "2025-09-15T04:41:03.627346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demo: run Grad-CAM on one validation batch\n",
    "for (mel_b, hand_b), y_b in val_xy.take(1):\n",
    "    heatmaps, chosen_classes, preds = grad_cam(model, mel_b, hand_b)\n",
    "    n = min(10, mel_b.shape[0])  # Show up to 10 samples\n",
    "    for i in range(n):\n",
    "        pred_idx = int(np.argmax(preds[i]))\n",
    "        true_idx = int(y_b.numpy()[i])\n",
    "        title = f\"True: {CFG.classes[true_idx]} | Pred: {CFG.classes[pred_idx]}\"\n",
    "        visualize_cam_on_mel(mel_b[i].numpy(), heatmaps[i], title=title)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:08.152480Z",
     "iopub.status.busy": "2025-09-15T04:41:08.152233Z",
     "iopub.status.idle": "2025-09-15T04:41:12.376987Z",
     "shell.execute_reply": "2025-09-15T04:41:12.376309Z",
     "shell.execute_reply.started": "2025-09-15T04:41:08.152419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: val_xy should be your tf.data dataset returning ((mel, hand), label)\n",
    "for (mel_b, hand_b), y_b in val_xy.take(1):\n",
    "    # Run Grad-CAM (auto-detects last Conv2D if conv_layer_name=None)\n",
    "    heatmaps, chosen_classes, preds = grad_cam(model, mel_b, hand_b, conv_layer_name=None)\n",
    "\n",
    "    # Number of samples to visualize (up to 10)\n",
    "    n = min(10, mel_b.shape[0])\n",
    "    for i in range(n):\n",
    "        pred_idx = int(np.argmax(preds[i]))\n",
    "        # Handle tensor or numpy labels\n",
    "        true_idx = int(y_b.numpy()[i]) if hasattr(y_b, \"numpy\") else int(y_b[i])\n",
    "        title = f\"True: {CFG.classes[true_idx]} | Pred: {CFG.classes[pred_idx]}\"\n",
    "        visualize_cam_on_mel(mel_b[i].numpy(), heatmaps[i], title=title)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:12.378096Z",
     "iopub.status.busy": "2025-09-15T04:41:12.377871Z",
     "iopub.status.idle": "2025-09-15T04:41:17.987898Z",
     "shell.execute_reply": "2025-09-15T04:41:17.987176Z",
     "shell.execute_reply.started": "2025-09-15T04:41:12.378078Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tf-keras-vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:17.989160Z",
     "iopub.status.busy": "2025-09-15T04:41:17.988934Z",
     "iopub.status.idle": "2025-09-15T04:41:18.024072Z",
     "shell.execute_reply": "2025-09-15T04:41:18.023338Z",
     "shell.execute_reply.started": "2025-09-15T04:41:17.989137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Integrated Gradients for spectrogram input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "\n",
    "def integrated_gradients(model, mel_batch, hand_batch, target_class=None, n_samples=50):\n",
    "    attributions = []\n",
    "\n",
    "    for i in range(len(mel_batch)):\n",
    "        mel_input = tf.convert_to_tensor(mel_batch[i:i+1])\n",
    "        hand_input = tf.convert_to_tensor(hand_batch[i:i+1])\n",
    "\n",
    "        # Baseline: all zeros\n",
    "        mel_baseline = tf.zeros_like(mel_input)\n",
    "        hand_baseline = tf.zeros_like(hand_input)\n",
    "\n",
    "        # Interpolate\n",
    "        alphas = tf.linspace(0.0, 1.0, n_samples)\n",
    "        mel_interp = mel_baseline + alphas[:, None, None, None] * (mel_input - mel_baseline)\n",
    "        hand_interp = hand_baseline + alphas[:, None] * (hand_input - hand_baseline)\n",
    "\n",
    "        # Expand batch\n",
    "        mel_interp = tf.cast(mel_interp, tf.float32)\n",
    "        hand_interp = tf.cast(hand_interp, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch([mel_interp, hand_interp])\n",
    "            preds = model([mel_interp, hand_interp], training=False)\n",
    "\n",
    "            if target_class is None:\n",
    "                target_class = tf.argmax(preds[0])\n",
    "\n",
    "            scores = preds[:, target_class]\n",
    "\n",
    "        grads = tape.gradient(scores, [mel_interp, hand_interp])\n",
    "        mel_grads, hand_grads = grads\n",
    "\n",
    "        # Average over steps\n",
    "        avg_mel_grads = tf.reduce_mean(mel_grads, axis=0).numpy()\n",
    "        avg_hand_grads = tf.reduce_mean(hand_grads, axis=0).numpy()\n",
    "\n",
    "        # Normalize mel\n",
    "        mel_attr = avg_mel_grads * (mel_input[0].numpy() - mel_baseline[0].numpy())\n",
    "        mel_attr = (mel_attr - mel_attr.min()) / (mel_attr.max() - mel_attr.min() + 1e-8)\n",
    "\n",
    "        # Normalize hand\n",
    "        hand_attr = avg_hand_grads * (hand_input[0].numpy() - hand_baseline[0].numpy())\n",
    "        hand_attr = (hand_attr - hand_attr.min()) / (hand_attr.max() - hand_attr.min() + 1e-8)\n",
    "\n",
    "        attributions.append((mel_attr, hand_attr))\n",
    "\n",
    "    return attributions\n",
    "\n",
    "def visualize_ig_on_mel(mel, ig, title=\"Integrated Gradients\"):\n",
    "    \"\"\"Overlay IG heatmap on mel spectrogram.\"\"\"\n",
    "    mel2d = mel[..., 0] if mel.ndim == 3 else mel\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(mel2d, origin=\"lower\", aspect=\"auto\", cmap=\"magma\")\n",
    "    plt.imshow(ig, origin=\"lower\", aspect=\"auto\", cmap=\"hot\", alpha=0.4)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:18.024997Z",
     "iopub.status.busy": "2025-09-15T04:41:18.024813Z",
     "iopub.status.idle": "2025-09-15T04:41:22.510377Z",
     "shell.execute_reply": "2025-09-15T04:41:22.509798Z",
     "shell.execute_reply.started": "2025-09-15T04:41:18.024982Z"
    }
   },
   "outputs": [],
   "source": [
    "# SHAP for handcrafted features\n",
    "import shap\n",
    "\n",
    "def explain_handcrafted_with_shap(model, hand_samples, background_samples, max_display=15):\n",
    "    \"\"\"\n",
    "    Use SHAP to explain handcrafted features.\n",
    "    Args:\n",
    "        model              : trained dual-input model\n",
    "        hand_samples       : handcrafted feature array (N, F)\n",
    "        background_samples : background handcrafted features (for SHAP baseline)\n",
    "        max_display        : number of features to display\n",
    "    \"\"\"\n",
    "    # Wrap the model so it only takes handcrafted input\n",
    "    def f_handcrafted(x):\n",
    "        # Expand x to match batch size and pass dummy mel\n",
    "        dummy_mel = np.zeros((x.shape[0], *model.input[0].shape[1:]), dtype=np.float32)\n",
    "        preds = model([dummy_mel, x], training=False)\n",
    "        return preds.numpy()\n",
    "\n",
    "    explainer = shap.Explainer(f_handcrafted, background_samples)\n",
    "    shap_values = explainer(hand_samples)\n",
    "\n",
    "    # Plot summary\n",
    "    shap.summary_plot(shap_values, hand_samples, plot_type=\"bar\", max_display=max_display)\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:22.511259Z",
     "iopub.status.busy": "2025-09-15T04:41:22.511073Z",
     "iopub.status.idle": "2025-09-15T04:41:28.388997Z",
     "shell.execute_reply": "2025-09-15T04:41:28.388402Z",
     "shell.execute_reply.started": "2025-09-15T04:41:22.511245Z"
    }
   },
   "outputs": [],
   "source": [
    "for (mel_b, hand_b), y_b in val_xy.take(5):\n",
    "    heatmaps, _, _ = grad_cam(model, mel_b, hand_b)\n",
    "    visualize_cam_on_mel(mel_b[0].numpy(), heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:28.390095Z",
     "iopub.status.busy": "2025-09-15T04:41:28.389849Z",
     "iopub.status.idle": "2025-09-15T04:41:32.616376Z",
     "shell.execute_reply": "2025-09-15T04:41:32.615685Z",
     "shell.execute_reply.started": "2025-09-15T04:41:28.390078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: val_xy should be your tf.data dataset returning ((mel, hand), label)\n",
    "for (mel_b, hand_b), y_b in val_xy.take(1):\n",
    "    # Run Grad-CAM (auto-detects last Conv2D if conv_layer_name=None)\n",
    "    heatmaps, chosen_classes, preds = grad_cam(model, mel_b, hand_b, conv_layer_name=None)\n",
    "\n",
    "    # Number of samples to visualize (up to 10)\n",
    "    n = min(10, mel_b.shape[0])\n",
    "    for i in range(n):\n",
    "        pred_idx = int(np.argmax(preds[i]))\n",
    "        # Handle tensor or numpy labels\n",
    "        true_idx = int(y_b.numpy()[i]) if hasattr(y_b, \"numpy\") else int(y_b[i])\n",
    "        title = f\"True: {CFG.classes[true_idx]} | Pred: {CFG.classes[pred_idx]}\"\n",
    "        visualize_cam_on_mel(mel_b[i].numpy(), heatmaps[i], title=title)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:32.617565Z",
     "iopub.status.busy": "2025-09-15T04:41:32.617325Z",
     "iopub.status.idle": "2025-09-15T04:41:39.814603Z",
     "shell.execute_reply": "2025-09-15T04:41:39.813888Z",
     "shell.execute_reply.started": "2025-09-15T04:41:32.617548Z"
    }
   },
   "outputs": [],
   "source": [
    "for (mel_b, hand_b), y_b in val_xy.take(1):\n",
    "    attributions = integrated_gradients(model, mel_b, hand_b)\n",
    "    mel_attr, hand_attr = attributions[0]  # take first sample\n",
    "\n",
    "    visualize_ig_on_mel(mel_b[0].numpy(), mel_attr)  # heatmap on spectrogram\n",
    "    print(\"Hand feature attribution:\", hand_attr)    # show feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T04:41:39.816580Z",
     "iopub.status.busy": "2025-09-15T04:41:39.815649Z",
     "iopub.status.idle": "2025-09-15T04:41:51.100143Z",
     "shell.execute_reply": "2025-09-15T04:41:51.099485Z",
     "shell.execute_reply.started": "2025-09-15T04:41:39.816535Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: val_xy should be your tf.data dataset returning ((mel, hand), label)\n",
    "for (mel_b, hand_b), y_b in val_xy.take(1):\n",
    "    # --- Grad-CAM ---\n",
    "    heatmaps, chosen_classes, preds = grad_cam(model, mel_b, hand_b, conv_layer_name=None)\n",
    "\n",
    "    # --- Integrated Gradients ---\n",
    "    attributions = integrated_gradients(model, mel_b, hand_b)\n",
    "\n",
    "    # Number of samples to visualize (up to 10)\n",
    "    n = min(10, mel_b.shape[0])\n",
    "    for i in range(n):\n",
    "        pred_idx = int(np.argmax(preds[i]))\n",
    "        true_idx = int(y_b.numpy()[i]) if hasattr(y_b, \"numpy\") else int(y_b[i])\n",
    "        title = f\"True: {CFG.classes[true_idx]} | Pred: {CFG.classes[pred_idx]}\"\n",
    "\n",
    "        # Grad-CAM heatmap visualization\n",
    "        visualize_cam_on_mel(mel_b[i].numpy(), heatmaps[i], title=title)\n",
    "\n",
    "        # Integrated Gradients visualization\n",
    "        mel_attr, hand_attr = attributions[i]\n",
    "        visualize_ig_on_mel(mel_b[i].numpy(), mel_attr, title=title)\n",
    "        print(f\"Hand-crafted feature attribution for sample {i}: {hand_attr}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes & tips\n",
    "\n",
    "If you prefer a specific conv layer (e.g. the last conv block), pass its name in conv_layer_name=\"conv_tail_identity\" (or whatever your layer is named).\n",
    "\n",
    "If your model's inputs are named differently than \"mel\" and \"handcrafted\", the _pack_inputs_for_model will pass positional inputs; you can adapt to named keys as needed.\n",
    "\n",
    "This version uses first-order Grad-CAM which is reliable, widely used, and compatible with GPU/CuDNN RNN acceleration. Grad-CAM++ (higher-order) gives finer localization but requires ops that may not support second/third derivatives on GPU; for reproducible training & visualization I recommend this first-order Grad-CAM.\n",
    "\n",
    "If any file is silent and librosa prints warnings (empty frequency tuning), you may ignore or filter those silent files during preprocessing.\n",
    "\n",
    "If you paste this block into your notebook it should run without the previous cuDNN / stacking / dtype errors. If you still see any error, paste the full traceback here and I’ll patch it immediately."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5614888,
     "sourceId": 9277143,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
